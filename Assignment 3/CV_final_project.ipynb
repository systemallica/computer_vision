{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV_final_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mh4PAn0yA6Wu",
        "colab_type": "text"
      },
      "source": [
        "# Computer vision Final project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9e0FMgbBBOC",
        "colab_type": "text"
      },
      "source": [
        "Fetch data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3011nqQEhnx",
        "colab_type": "code",
        "outputId": "fb8ddde5-4675-467b-8215-f6161f902dd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "!wget -nc http://host.robots.ox.ac.uk/pascal/VOC/voc2009/VOCtrainval_11-May-2009.tar\n",
        "!tar -xf VOCtrainval_11-May-2009.tar --totals\n",
        "\n",
        "voc_root_folder = \"/content/VOCdevkit/VOC2009\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-16 07:32:57--  http://host.robots.ox.ac.uk/pascal/VOC/voc2009/VOCtrainval_11-May-2009.tar\n",
            "Resolving host.robots.ox.ac.uk (host.robots.ox.ac.uk)... 129.67.94.152\n",
            "Connecting to host.robots.ox.ac.uk (host.robots.ox.ac.uk)|129.67.94.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 935534080 (892M) [application/x-tar]\n",
            "Saving to: ‘VOCtrainval_11-May-2009.tar’\n",
            "\n",
            "VOCtrainval_11-May- 100%[===================>] 892.19M  9.34MB/s    in 1m 41s  \n",
            "\n",
            "2020-04-16 07:34:38 (8.83 MB/s) - ‘VOCtrainval_11-May-2009.tar’ saved [935534080/935534080]\n",
            "\n",
            "Total bytes read: 935536640 (893MiB, 252MiB/s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1sqYb9j6gNR",
        "colab_type": "text"
      },
      "source": [
        "Build training(65%), validation(20%) and test(15%) sets from the data.\n",
        "\n",
        "The data provided consists of a set of images; each image has an annotation file giving a bounding box and object class label for each object in one of the twenty classes present in the image. Note that multiple objects from multiple classes may be present in the same image.\n",
        "\n",
        "A subset of images are also annotated with pixel-wise segmentation of each object present, to support the segmentation competition.\n",
        "\n",
        "The segmentations are like this:\n",
        "- Object segmentation:\n",
        "pixel indices correspond to the first, second, third object etc.\n",
        "\n",
        "- Class segmentation:\n",
        "pixel indices correspond to classes in alphabetical order (1=aeroplane, 2=bicycle, 3=bird, 4=boat, 5=bottle, 6=bus, 7=car , 8=cat, 9=chair, 10=cow, 11=diningtable, 12=dog, 13=horse, 14=motorbike, 15=person, 16=potted plant, 17=sheep, 18=sofa, 19=train, 20=tv/monitor) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FY3Wxmy6k6k",
        "colab_type": "code",
        "outputId": "4fa2bdd1-f0bc-48d8-feb0-20d3b5ae4b12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "root_path = \"/content/VOCdevkit/VOC2009\"\n",
        "images_path = \"/JPEGImages\"\n",
        "annotation_path = \"/Annotations\"\n",
        "class_segmentation_path = \"/SegmentationClass\"\n",
        "object_segmentation_path = \"/SegmentationObject\"\n",
        "\n",
        "# Get list of img ids\n",
        "img_ids = [os.path.splitext(filename)[0] for filename in os.listdir(root_path + images_path)]\n",
        "# Get list of ids of images prepared for segmentation\n",
        "segmentation_ids = [os.path.splitext(filename)[0] for filename in os.listdir(root_path + class_segmentation_path)]\n",
        "\n",
        "# Seed necessary to get the same datasets each time the cell is run\n",
        "seed = 12374\n",
        "\n",
        "# Training set = 65%, validation + test = 35%\n",
        "train_ids, valtest = train_test_split(img_ids, test_size=0.35, random_state=seed)\n",
        "\n",
        "# Validation = 20%, test = 15%\n",
        "validation_ids, test_ids = train_test_split(valtest, test_size=0.43, random_state=seed)\n",
        "\n",
        "# Only some images are prepared for segmentation, so the data subsets are filtered for this task\n",
        "train_ids_segmentation = list(filter(lambda id: id in segmentation_ids, train_ids))\n",
        "validation_ids_segmentation = list(filter(lambda id: id in segmentation_ids, validation_ids))\n",
        "test_ids_segmentation = list(filter(lambda id: id in segmentation_ids, test_ids))\n",
        "\n",
        "print(len(train_ids))\n",
        "print(len(train_ids_segmentation))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5081\n",
            "1019\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}